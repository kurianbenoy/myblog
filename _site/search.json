[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Kurian Benoy",
    "section": "",
    "text": "Hi, I’m Kurian Benoy, a ML Engineer who is working in sentient.io. I have been building impactful data science projects over the past few years."
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code."
  },
  {
    "objectID": "index.html#bio",
    "href": "index.html#bio",
    "title": "Kurian Benoy",
    "section": "Bio",
    "text": "Bio\nHi, I’m Kurian Benoy, a ML Engineer who is working in sentient.io. I have been building impactful data science projects over the past few years."
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "kurianbenoy",
    "section": "",
    "text": "::: {.column-page}\n\n\n\n\n\n\n\n\n  \n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\n\n\nDec 18, 2022\n\n\nTristan O’Malley\n\n\n\n\n\n\n  \n\n\n\n\nGetting featured in Spaces of the week and my latest two gradio spaces\n\n\n\n\n\n\n\nhuggingface\n\n\nDeep learning\n\n\nfastai\n\n\n\n\n\n\n\n\n\n\n\nJul 6, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nStarting an open-source project - Malayalam Text Classifier\n\n\n\n\n\n\n\nmalayalamtextmodels\n\n\nmalayalam\n\n\nNLP\n\n\nopensource\n\n\nML\n\n\nDeep learning\n\n\nSMC\n\n\n\n\n\n\n\n\n\n\n\nMay 30, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDeep Learning For Coders with fastai Couse - Lesson 3\n\n\n\n\n\n\n\nfastbook\n\n\nmyself\n\n\nML\n\n\nDeep learning\n\n\nfastai\n\n\njourney\n\n\n\n\n\n\n\n\n\n\n\nMay 24, 2022\n\n\nkurianbenoy\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDeep Learning For Coders with fastai Couse - Lesson 3\n\n\n\n\n\n\n\nfastbook\n\n\nmyself\n\n\nML\n\n\nDeep learning\n\n\nfastai\n\n\njourney\n\n\n\n\n\n\n\n\n\n\n\nMay 10, 2022\n\n\nkurianbenoy\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDeep Learning For Coders with fastai Couse - Lesson 2\n\n\n\n\n\n\n\nfastbook\n\n\nmyself\n\n\nML\n\n\nDeep learning\n\n\nfastai\n\n\njourney\n\n\n\n\n\n\n\n\n\n\n\nMay 3, 2022\n\n\nkurianbenoy\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDeep Learning For Coders with fastai Couse - Lesson 1\n\n\n\n\n\n\n\nfastbook\n\n\nmyself\n\n\nML\n\n\nDeep learning\n\n\nfastai\n\n\njourney\n\n\n\n\n\n\n\n\n\n\n\nApr 26, 2022\n\n\nkurianbenoy\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPractical Deep Learning for Coders - Lesson 0\n\n\n\n\n\n\n\nfastbook\n\n\nmyself\n\n\nML\n\n\nDeep learning\n\n\nfastai\n\n\njourney\n\n\n\n\n\n\n\n\n\n\n\nApr 26, 2022\n\n\nkurianbenoy\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFirst Vacation Experience\n\n\n\n\n\n\n\nTravel\n\n\nLife\n\n\n\n\n\n\n\n\n\n\n\nFeb 16, 2022\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/2022-04-26-fastai-51.html",
    "href": "posts/2022-04-26-fastai-51.html",
    "title": "Deep Learning For Coders with fastai Couse - Lesson 1",
    "section": "",
    "text": "Jeremy said there are two types of student:\n\nUQ student who attend lessons in class(almost 350 there and also 100 remotely)\nfastai live\n\nIf you have N95, K95 it’s live\nHaving study buddies, will be very helpful to pursue a study group. This is the version 5 of this course, and it’s amazing things have changed. Identifying a bird in 2015, was virtually impossible. Images are made of numbers\nDeep learning moves so fast, since it’s using Dalle-2 input images and generate twitter bios. Happy sisiphus, using twitter bios to generate computer visions. Nick spends less than 2 minutes, and it’s very helpful for creative people.\nNow the Pathways language model, read english models. It answers question with explanation. Explains jokes.\n@Tanishq Abraham https://ethics.fast.ai/ - created by learning\nRadek build caps.fast.ai, and Radek got into NvidaAI\nHe is a homeschooler, he taught about Paul Lockhart & David Perkins with inspiration from fast.ai. You will go into as much technical stuff, yet you will learn who finds cool stuff.\nHe wrote an awesome book and this course, we are not using any material from directly. Multiple people learn in a different way, with different source. Always read one portion of book after each chapter. No content from fastbook in this book.\nEntilitic, he build a good medical company. Almost 6 million people watched his videos. It’s amazing to see why lot of people like in tesla, OpenAI they use the course.\nWhy couldn’t we build a bird recognizer in 2012?\n\nTaking histopothical images. They used computer vision techniques\nThey got big team of datascientist, mathematicans with lot of features\nThe project took years\nin deep learning(it was not in their radar)\nVery succesfull, neural network build these features on ourself.\nMathew D Zeiler & Rob Fergus(and actual weights)\nCombine all features to learn and go slowly with things. Don’t come up with any of these.\n\nImage based algorithms, are not for images. Image for music classification by Deolho, Ethan sutin sounds from image recognizer. Pictures from music classification, with some creativity\nLots of data is a myth by companies who sell data processing units. Lot of free resources. Transfer learning & Pytorch vs Tensorflow. Tensorflow is now slowly dying in research. IN research repos, tensorflow research. https://www.assemblyai.com/blog/pytorch-vs-tensorflow-in-2022/\nWill be increasingly released, that pytorch will sustain. Lot of hairy code in pytorch. Writing lot of code is bad. Always less code is better.\nWeightDecay with Adam. He is using JupyterNotebook for slides. Insane\nhttps://github.com/fastai/fastbook/blob/master/16_accel_sgd.ipynb(AdamW explained here)\nPets notebooks\nFastdownload resize_image(), thumb()\nYou spend lot of time of building and loading models. Like in compiler course. Jeremy uses functional kind of programming, works for him very well. He uses map and all lot. The five things in Datablock based on 100 and 100s of project:\n\nblocks\nget_items\nsplitter\nBatch_tfms(optional)\nget_y\nitem_tfms\n\nWithout validation data, it won’t allow to train. parent_label, return parent folder. we saved as forests or birds. We need same size. Idea to do quickly, why not publish vision_learners with pets dataset.\nJeremy used RiseJS Jupyter Notebook for presentation. https://rise.readthedocs.io/en/stable/\nJupter Notebooks, for blogging, writing books testing CI/CD with notebooks in parallel.\nWe are still scratching the surface. Lot of marketing out there, some of first open source course available. The deep learning when it broke X, y, z in domain. In NLP it breaks lot of stuff\nWhat’s really go in on : in arthur samuel with graph. The graphs are build with gv2 in jupyter notebook. Deploying models in ML is a bit tricky. But it’s just predict and shows results.\nSo after first lesson:\n\nIf you know python, this is easy\nIf don’t know python, it’s very difficult\n\nRegardless as where you are. Experiment and do something more complex, do more categories. Go ahead and push yourself a little bit, but not much. Then present your work. Do stuff on things where you are interested. Students moving to disaster resilence with lot of other things.\nSplunk a patentent project using fradusters identification, envision\nJeremy says:\n\nRead questionnares at end of book\nAlway look output of your images\nLook at quiz question before you are here."
  },
  {
    "objectID": "posts/2022-04-26-fastai-50.html",
    "href": "posts/2022-04-26-fastai-50.html",
    "title": "Practical Deep Learning for Coders - Lesson 0",
    "section": "",
    "text": "Last few weeks, I enrolled for the live cohort of Deep Learning For Coders with fastai Couse which is going to be taken by Jeremy Howard. It’s’ a previlege at the same time, a dream come true moment for me, as a fastai student who took some part of fast.ai from the year 2018.\nWhatever I have done in ML can be partly attributed to the way and the Jeremy motivated students to be world class researchers. The fastai course has seen lot of success stories from folks like Aman Arora, Deoldify creator, Sanyam Bhutani, Even Oldrige, Jason Antic Radek, Zach Mueller, Wayde Gilliam and much more. Jeremy has inspired and enabled multiple people to be practitioners in Deep Learning. {bhuvani an example}\nI still feel I am a late boomer, and due to pursuing a work along with academics. I am in a position to be extremely careful with what I spend time with and things I do.\nI will do following:\n\nTry out every notebook given by Jeremy during class and writes in Kaggle\nbreath and look through pytorch tutorials\nWrite blogpost every week with lesson summary and occasionally on new things I learning during course.\nParticipate in NLP competition provided by jeremy link\n\nI won’t do:\n\nWon’t read Pytorch book(even though it’s very tempting to do)\nBe active in twitter during course\nRead EDA notebooks\nWon’t write any notebooks in tensorflow :)"
  },
  {
    "objectID": "posts/2022-07-06-gradio_spaces.html",
    "href": "posts/2022-07-06-gradio_spaces.html",
    "title": "Getting featured in Spaces of the week and my latest two gradio spaces",
    "section": "",
    "text": "I recently created two gradio based webapps, and one of my spaces - Paddy Doctor got featured in list of hugging face Spaces of the week.\n\n\n\nimage\n\n\nBoth gradio apps based on two kaggle competitions which I have been participating in. Both are on computer vision models with one to identify the type of disease in the paddy crop and another to identify the name of flowers(which I am terribly bad at remembering names).\nDo checkout the links below for the spaces\nPaddy Doctor\nIdentify which flower"
  },
  {
    "objectID": "posts/2022-04-20-Letter.html",
    "href": "posts/2022-04-20-Letter.html",
    "title": "A letter to my future self",
    "section": "",
    "text": "Hey Kurian in future,\n\nDon’t marry any technologies, and don’t just be associated to any particular field, programming language. Remember about the time your username was django_master and luckily getting selected to first Pycon talk changed everything.\nAlways respect & care parents & elders\nRemember everything is just Maya Maya (just pointless) as stated by wisest of wise person.\nWhen you are thinking goosebumps or feel proud of something, remember that sooner or later there is a low point coming.\nAlways look back to your past and be grateful for everything. Also look at your core and remember where you started.\n\nSigning off, Kurian"
  },
  {
    "objectID": "posts/2022-02-16-first_vacation.html",
    "href": "posts/2022-02-16-first_vacation.html",
    "title": "First Vacation Experience",
    "section": "",
    "text": "I had taken my longest vacation from work in past week for four days. It was really enjoyable, and I was planning to do that for a long time. Yet due to Covid lockdown and bunch of other things it was late.Also the planning part for the vaction was really interesting at the same time hectic. My initial plan was to visit a old palace ie Padmnapuram palace in Thuckalay, Tamil Naidu. Unfortunately, it didn’t work out.\nSo I pivoted my plan to stay in any hotel/resort. Before telling about the experience let me tell, what motivated me to take my vacation at the first place. It was an article by Randy Au who gave a really useful insight why taking vacation is important with a realistic angle. In the article the lessons on why we are not important to any organization and planning aspect is well covered. Randy Au answered my question on how to treat travelling as a hobby as well when I asked in a Twitter AMA.\nI applied for four days of leave well in advance before planning where I am going to plan. Then I started my journey of hunting the perfect place to stay. After almost 20+ hotel enquiries and also trying to accomodate everyone in my family to come with me. The outcome was kind of final. Unfortunately not everyone in my family was willing to come with me except my mother. After a lot of searching we decided to book the hotel at Mango Meadows and set aside one day to travel with my family in Kochi(by spending time on shopping & a buffet dinner).\nAbout the resort I stayed. Mango meadows resort is an excellent place and is an agricultural themed park. The place is filled with natural beauty and bought me closer to nature during the stay. Unlike typical resorts where you have just one small area, here you have 30 acres of land with lot of facilities like a amusment park. For me some of the memorable experiences during two day stay at Mango Meadows was swimming in pay pool, then cycling followed by bumpy ride in london metro. Staff were excellent and 5 stars review for the resort.\nSo was all the travelling really worth it? Back to work next day back I had lot of messages and 70+ emails to answer. This proved everything Randy said, and slowly one day I will also get better at vacationing. Also we started planning for our next big trip to Armenia which will materialize one day hopefully."
  },
  {
    "objectID": "posts/2022-05-30-malayalamtext-0.html",
    "href": "posts/2022-05-30-malayalamtext-0.html",
    "title": "Starting an open-source project - Malayalam Text Classifier",
    "section": "",
    "text": "TLDR: Kurian has committed to start an open-source project for Text classification tasks in Malayalam which is going to build as an open-source project under SMC community."
  },
  {
    "objectID": "posts/2022-05-30-malayalamtext-0.html#why-i-am-starting-this-project",
    "href": "posts/2022-05-30-malayalamtext-0.html#why-i-am-starting-this-project",
    "title": "Starting an open-source project - Malayalam Text Classifier",
    "section": "Why I am starting this project?",
    "text": "Why I am starting this project?\nI have been doing the fastai course since 2018. Yet I have been taking it seriously probably, only after I bought the book Deep Learning for Coders with FastAI & Pytorch almost one year back. This year I took the fastai v5 course, and I feel it’s time to follow a piece of advice which I have heard multiple times.\n\nImportant: Jeremy Howard, who is teaching this course and wrote the book prompts you to take what you learned and apply it to something that has meaning for you. (This is something that most of those who’ve found any success with the course emphasise repeatedly.)"
  },
  {
    "objectID": "posts/2022-05-30-malayalamtext-0.html#problem-domain",
    "href": "posts/2022-05-30-malayalamtext-0.html#problem-domain",
    "title": "Starting an open-source project - Malayalam Text Classifier",
    "section": "Problem Domain",
    "text": "Problem Domain\nAccording to huggingface tasks page:\n\nText Classification is the task of assigning a label or class to a given text. Some use cases are sentiment analysis, natural language inference, and assessing grammatical correctness.\n\nMalayalam is a highly inflectional and agglutinative language compared to other languages. The quantitative complexity of Malayalam classification was explained in this paper. The computer still doesn’t seem to have understood the basic behaviour of the language to do text classification. Malayalam is a language which morphologically complex making it even more difficult.\nVery few people seem to have applied techniques in deep learning in Malayalam, and it seems to be a good place to see if really deep learning techniques can be applied in my mother tongue, Malayalam. A lot of progress in other languages has happened and in general NLP, yet it’s a good time to see if it works in Indic languages like Malayalam."
  },
  {
    "objectID": "posts/2022-05-30-malayalamtext-0.html#why-text-classification-is-interesting",
    "href": "posts/2022-05-30-malayalamtext-0.html#why-text-classification-is-interesting",
    "title": "Starting an open-source project - Malayalam Text Classifier",
    "section": "Why Text classification is interesting?",
    "text": "Why Text classification is interesting?\nI believe working on tasks like Text classification is way more difficult when we are working in low-resource languages like Malayalam. Yet when working on problems like this, you realize what are things you take for granted in the English language.\nIn the English language, there are plenty of labelled datasets on any problem set you to want. A lot of articles and blogs have been written on how to apply various NLP techniques in English. When it comes to Malayalam, there is just a handful of people who have tried and applied this in Malayalam.\n\nNote to myself: Will is more important than Skill and it’s important to be tenacious here.\n\nI believe this is here, it’s very important to believe in one’s tenacity and try out new things in a field where very less research happening, and there are no proper open datasets for researchers to work on. This is why I feel this project can be challenging, and my approach is to see if the latest transformer approaches can do something or not."
  },
  {
    "objectID": "posts/2022-05-30-malayalamtext-0.html#previous-work-vaaku2vec",
    "href": "posts/2022-05-30-malayalamtext-0.html#previous-work-vaaku2vec",
    "title": "Starting an open-source project - Malayalam Text Classifier",
    "section": "Previous work: Vaaku2Vec",
    "text": "Previous work: Vaaku2Vec\nThe most important work in Malayalam text classification as far as I know is Vaaku2Vec project - State-of-the-Art Language Modeling and Text Classification in the Malayalam Language.\nAccording to their Github README:\n\nWe trained a Malayalam language model on the Wikipedia article dump from Oct, 2018. The Wikipedia dump had 55k+ articles. The difficulty in training a Malayalam language model is text tokenization since Malayalam is a highly inflectional and agglutinative language. In the current model, we are using an nltk tokenizer (will try better alternative in the future) and the vocab size is 30k. The language model was used to train a classifier which classifies a news into 5 categories (India, Kerala, Sports, Business, Entertainment). Our classifier came out with a whooping 92% accuracy in the classification task.\n\nIt was revolutionary at that time, to see deep learning techniques applied to get SOTA in Malayalam. IndicNLP as an organisation did a lot of work, from working on projects like Word2vec, Vaakk2vec etc. They worked on creating a Named entity recognition dataset for Malayalam etc. They conducted Devsprints in colleges like Model Engineering college… and presented their work in Pycon India and Kochi Python. Most of the work was done by Adam Shamsudeen and Kamal K Raj."
  },
  {
    "objectID": "posts/2022-05-30-malayalamtext-0.html#whats-the-plan-for-the-project",
    "href": "posts/2022-05-30-malayalamtext-0.html#whats-the-plan-for-the-project",
    "title": "Starting an open-source project - Malayalam Text Classifier",
    "section": "What’s the plan for the project?",
    "text": "What’s the plan for the project?\n\nImportant: Cervantes once wrote that “the journey is better than the inn”, which means that the process is more valuable than the destination.\n\nAt moment, the project doesn’t have any concrete goals and it’s just me who is working in my free time.\nI have created a few issues and my next blog post will be on creating a baseline model on a private dataset that a few kind folks shared with me. I expect the dataset creation to be an iterative task. I am looking forward to blogging about what I work on and stumble upon in each stage of the project.\nWhen I was looking for where I wanted to create this as an open-source project obviously, I choose Swathanthra Malayalam Community because:\n\nI feel SMC as an organization played a pivotal part in revolutionizing Malayalam computing and has a strong community presence. They have made a lot of work by creating fonts, helping in internationalization efforts, …\nPeople like Santhosh Thottingal and Kavya Manohar have helped me a lot in my previous failed attempt to build TTS with deep learning in Malayalam.\nSome of the open-source projects made by SMC still survive like the website of Malayalam Speech Corpus which is impressive to me.\n\nI would like to thank the following people for all the support and motivation they have given me in starting this open-source project on this occasion:\n\nAlex Strick van Linschoten\nSanthosh Thottingal and Kavya Manohar\nAshwin Jayaprakash"
  },
  {
    "objectID": "posts/2022-05-10-fastai-53.html",
    "href": "posts/2022-05-10-fastai-53.html",
    "title": "Deep Learning For Coders with fastai Couse - Lesson 3",
    "section": "",
    "text": "There is a minor delay in streaming the lessons today. Lesson 1, 2 are easy for everyone, while usually lesson 3 is more hard defenitely.\nFastai lesson 0, https://kurianbenoy.com/2021-06-16-fastgroup-1/\nIdea of running notebooks, understanding everything in that particular lesson. Then try to reproduce.(clean notebook approach, to test your understand) If you can do with different dataset, ie the hard time.\nAlways study done, with other people is the best activity. This week, with the best no of votes.\nMy work also got featured, with lot of votes.\nToday Jeremy featured, a gradient descend platform. He has been using it for paperspace, and it’s totally amazing. He got something done by them. He is going to add walk throughs of various lessons.\nIn lesson2, it’s not taking a particular lesson and use in particular platform. There are two important pieces:\n\nTraining piece\nDeployment piece\n\ntrain.ipynb app.ipynb - inference\nFinding good image models, by using and looking at a better architecture.\nHe tried levit_models, didn’t work really great\ntimm.[25.00] - experiment with latest models. It got really good accuracy with 0.0005. Now there are lot of good architectures, which beats resnet really well. 22,000 categories of images. If you can do better, go do it.\n37 breeds, then in case of category. Usually that category is in the vocab of dataloaders.\nJust run learn.model. Understand what is stuff in learn?\nIn deep learning lot of trees\n[30:00] get modules in pytorch. Layer norm things\nWhat are these numbers? What are these parameters. How can these number figure out it’s a particular dog or not\nPartial application, it’s just something in lot of languages. How applying quardartic\ndata matching function with data, adding noise with data torch.linspace which goes from -2 to +4\nCreate a plot quadratic, which helps in interacting. Using @interact most simple and common loss functions MSE\nRerun with MSE. Now add MSE, and see if it get’s better or worse. This is a manual process, and does he tweak. When we move up, does the loss get’s better. Or if it decreases, does loss goes down.\nThe derivate is a function, which tells if we increase does it increase or decrease. In pytorch, youu can automtically done by pytorch.\nipythonwidgets using intereact\nreturn interact. Does mse made by pytorch interact\nRank 1 tensor, 1 D tensor\n[49:00] onwards follow the calculation again, and try to do it again. Now it got and calculated the loss.\nWith torch.no_grad():\n\ninner part of machine learning code. This is basic optimizer. This is gradient descent. We calculate gradient, and then build models. Not following stuff in lesson [57:00] is not clear for me.\nWe learned deep learned. This is like how to draw an owl. This is how deep learning is, just go through the course.\nhttps://pytorch.org/tutorials/\nI want to be around 0.001 second. Doing grid search takes a lot of time. Training your good models, at the first day is not a big requirement. It’s very easy to get inputs & outputs, yet getting segmented output is way harder. The important number, learning_rate to calculate parameters.\nAfter break\nMathematical trip, we want to do a whole bunch of RELUs. We want lot’s of variables. Add all the relus together, then use with different bunch of behaviours. 1000s of RELUs\nSIngle operation except last layer, with matrix multiplication. Linear algebra, almost all time you need is matrix multiplcator. It’s multiplying and adding neural networks together. GPUs are so good at this.\nhttp://matrixmultiplication.xyz/\nfast.ai using excel for matrix multiplication. From [1:28:32]\nTitanic data, about who survived and who didnt’\nvalidation and metrics optimization. He is going to look into that Kaggle dataset."
  },
  {
    "objectID": "posts/2022-05-03-fastai-52.html",
    "href": "posts/2022-05-03-fastai-52.html",
    "title": "Deep Learning For Coders with fastai Couse - Lesson 2",
    "section": "",
    "text": "We walked through the first model, and learned that the stuff we learn in code. To build grizzly bears and teddy bears.\nRandomResized Question: Does randomresized crop duplicate the image – i.e. you get multiple copies and you ensure that all the parts of the image are used in training? or does it just make one crop?\nAlex’s question(didn’t understand)\nBuild a good model. Understand and took a look at data and see what can be done to clean this dataset, as you slowly progress on training models. Actually this technique is SUPER helpful-in a recent interview, Chris Deotte (4x Grandmaster) shared how these resizing techniques helped them win a solo gold\n4GB machine, class and holt occasionaly\nIn GPU, always run one things at a time.\nIf you are in yellow, always stop try. First go ahead and watch fully without understanding. Then watch again and follow time. This is an unusual way.\n+1 for what Jeremy just said. This is how I do it … I just take notes where things were in the live lecture that I want to go back to later.\nPointed to tanishq tutorial on huggingface space. Hamel is even using github desktop, yet most of time we use terminal. In windows, we have WSL, just use ubuntu. He showed installing via ubuntu. Jeremy like Windows, but then there is linux environment with a good Deep jig. He uses 4GB CPU.\nGithub desktop in Ubuntu\nhttps://gist.github.com/berkorbay/6feda478a00b0432d13f1fc0a50467f1\nHe created a simple fastai model, uploading model in dogs_cat and then export.\nQuick gradio demo Catas vs Dog inference\nJupyter notebooks debugging with magic methods %magic\nLook at dict, numbers. Changing images predicted and issue with gradio using function to return gradio docs. Tensors is not supported at moment.\nJeremy with cats vs dogs classifier. The donny classifier which predicted as cat dog. Her daughter asked these questions(Cat mixed with Dog). Now we have a simple example."
  },
  {
    "objectID": "posts/2022-05-03-fastai-52.html#fastsetup",
    "href": "posts/2022-05-03-fastai-52.html#fastsetup",
    "title": "Deep Learning For Coders with fastai Couse - Lesson 2",
    "section": "fastsetup",
    "text": "fastsetup\nInstalling python and jupyter-notebooks.\nhttps://github.com/fastai/fastsetup\nA big issue in laptops. There is a setup_conda.sh. In linux or mac, don’t use that python.\nThat Python will mess stuff up. Running conda based systems is good.\nRun mamba install fastai mamba install -c fastchan jupyter nbdev\nSetting up huggingspace. Then using git & conda.\nDid dogs vs cats"
  },
  {
    "objectID": "posts/2022-05-03-fastai-52.html#gradio-with-webapps",
    "href": "posts/2022-05-03-fastai-52.html#gradio-with-webapps",
    "title": "Deep Learning For Coders with fastai Couse - Lesson 2",
    "section": "Gradio with webapps",
    "text": "Gradio with webapps\nAPI in gradio https://hf.space/embed/kurianbenoy/audioclassification/api\nWith live demo, we could have easily used it.\nfetch(‘https://hf.space/embed/kurianbenoy/audioclassification/+/api/predict/’, { method: “POST”, body: JSON.stringify({“data”:[ {“data”: null, “is_example”: true, “name”: “000003.ogg”}\n]}), headers: { “Content-Type”: “application/json” } }).then(function(response) { return response.json(); }).then(function(json_response){ console.log(json_response) })\nWith a Javascript app, there is not a lot of steps. There is an\nHow do you create a website for website. Without any software, you can run this file. That’s so cool about javascript. There is something cool called github pages\nHe used alembic theme. With a particular configuration. At top of any github pages, you should add three dashes. The world of javascript apps, he build this cool apps.\nYou don’t really need any money, any work with cool stuff.\nNext week we will be learning and diving into NLP. Then\nLot of frontend developers. Don’t be too afraid to run in javascript"
  },
  {
    "objectID": "posts/2022-05-24-fastai54.html",
    "href": "posts/2022-05-24-fastai54.html",
    "title": "Deep Learning For Coders with fastai Couse - Lesson 3",
    "section": "",
    "text": "https://web.archive.org/web/20210410111556/https://mlwave.com/kaggle-ensembling-guide/ https://forums.fast.ai/t/new-lr-finder-output/89236/3 https://docs.fast.ai/callback.schedule.html#Suggestion-Methods https://towardsdatascience.com/why-take-the-log-of-a-continuous-target-variable-1ca0069ee935 https://iliazaitsev.me/posts/2018/06/27/decision-trees https://www.kaggle.com/code/jhoward/how-random-forests-really-work"
  }
]